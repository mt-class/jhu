---
---
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
   <meta http-equiv="content-type" content="text/html; charset=utf-8" />
   <title>Homework 1: Alignment</title>

   <!-- Homepage CSS -->
   <link rel="stylesheet" href="screen.css" type="text/css" media="screen, projection" />

   <!-- MathJax -->
   <script type="text/javascript"
     src="https://d3eoax9i5htok0.cloudfront.net/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
   </script>
</head>
<body>

<div class="site">

  <div class="leftsidebar">
    <img src="img/rosetta.jpg" width="180" alt="The Rosetta Stone"/>
    <p><i><a href="http://en.wikipedia.org/wiki/Rosetta_Stone">The Rosetta 
Stone</a><br/> (image by 
      <a href="http://www.flickr.com/photos/calotype46/6683293633/">calotype46</a>)
   </i></p>

      <p>
        <b>Challenge 1</b>
        <ul>
          <li><b><a href="#overview">Overview</a></b></li>
          <li><b><a href="#starting">Getting Started</a></b></li>
          <li><b><a href="#challenge">The Challenge</a></b></li>
          <li><b><a href="#rules">Ground Rules</a></b></li>
          <li><b><a href="leaderboard.html">Leaderboard</a></b></li>
          <li><b><a href="https://piazza.com/jhu/spring2012/en600468">Discussion Forum</a></b></li>
        </ul>
      </p>
  </div>

<div class="content">
<a name="overview"></a>
<h1>Alignment <font color="lightgrey">: Challenge Problem 1</font></h1>
<div id="course" class="cv">

<p>Aligning words is a key task in data-driven machine translation. We start with
a large <b>parallel corpus</b> where the translation of each sentence
is known. So the input consists of sentence pairs like this one:
</p>

<center>
<p><i>le droit de permis passe donc de $ 25 à $ 500 . &mdash;
we see the licence fee going up from $ 25 to $ 500 .</i></p>
</center>

<p>It is relatively easy to obtain data in this form, though not completely trivial. 
This particular example is from the Canadian Hansards, proceedings of government
meetings that are required to be published in both English and French.
To align the sentences
we can exploit document boundaries and structural cues arising from the fact that the 
documents are translations of each other, such as the fact that translated sentences will be 
in the same order, of similar length, and so forth. The problem is that we
don't know the word-to-word correspondences in each sentence. That's where you come
in: <b>your challenge is to write a program that aligns the words automatically</b>. For the
sentence above, you might output the following correspondences:</p>

<p>
<center>
<i>le &mdash; the</i>, 
<i>droit &mdash; fee</i>, 
<i>permis&mdash; license</i>, 
<i>passe&mdash;going</i>,
<i>passe&mdash;up</i>,
<i>donc&mdash;from</i>,
<i>$ &mdash; $</i>,
<i>25 &mdash; 25</i>,
<i>à &mdash; to</i>,
<i>$ &mdash; $</i>,
<i>50 &mdash; 50</i>
</center>
</p>

<p>
Some words might be unaligned (e.g. <i>we</i> and <i>see</i>), while some words 
might be aligned to multiple words in the corresponding sentence (e.g. <i>passe</i>
is aligned to <i>going up</i>). Sometimes words aren't exact translations of each
other. That's ok: even experienced bilinguals will sometimes disagree on the best
alignment of a sentence.
But while word alignment doesn't capture every nuance, it is very useful for 
learning translation models or bilingual dictionaries.
</p>

<a name="starting"></a>
<h2>Getting Started</h2>

<p>Run this command:</p>

<p><pre>git clone https://github.com/alopez/dreamt.git</pre></p>

<p>We have provided you with a very simple aligner written in Python
and around two million words of the Canadian Hansards.  
The source code of the aligner is contained in file called <tt>align</tt>
under the directory <tt>aligner</tt>.
The baseline algorithm works in two phases. First, we train models.  
The aligner observes the training sentences and then gives a score, between 
0 and 1, to each possible alignment. The baseline aligner simply 
computes <a href="http://en.wikipedia.org/wiki/Dice's_coefficient">Dice's coefficient</a> 
between pairs of English and foreign words.  
It then aligns all pairs of words with a score over 0.5.
Run the baseline heuristic model 1,000 sentences
using the command:
</p>

<p><tt>align -n 1000 &gt; dice.a</tt></p>

<p>This runs the aligner and stores the output in <tt>dice.a</tt>. To view and
score the alignments, run this command:
</p>

<p><tt>grade &lt; dice.a</tt></p>

<p>This command scores the alignment quality by comparing the output alignments
against a set of human alignment annotations using a metric called the 
<b>alignment error rate</b>, which balances precision and recall of the
guessed alignments (<a href="http://aclweb.org/anthology-new/P/P00/P00-1056.pdf">paper</a>). Look at 
the terrible output of this heuristic model -- it's better than chance, but 
not any good. Try training on 10,000 sentences instead of 1,000, by specifying 
the change on the command line:</p>

<p><tt>align -n 10000 | grade</tt></p>

<p>Performance should improve, but only slightly!  Another experiment that 
you can do is change the threshold criterion used 
by the aligner.  How does this affect alignment error rate?</p>

<a name="challenge"></a>
<h2>The Challenge</h2>

<p>Your task for this assignment is to <b>improve the
alignment error rate as much as possible</b>. It shouldn't be hard to 
improve it at least some: you've probably noticed that thresholding a Dice 
coefficient is a bad idea because alignments don't compete against one 
another. A good way to correct this is with a probabilistic model like IBM Model 1.
It forces all of the English words in a sentence to compete 
as the explanation for each foreign word.
</p>

<p>Formally, IBM Model 1 is a probabilistic model that generates each word of 
the foreign sentence \( {\bf f} \) independently, conditioned on some word 
in the English sentence \( {\bf e} \).  
The likelihood of a particular alignment \( {\bf a} \) of the foreign sentence therefore 
factors across words: 
\( P({\bf f}, {\bf a} | {\bf e}) = \prod_i P(a_i = j | |{\bf e}|) \times P(f_i | e_j) \).  
In Model 1, we fix \( P(a_i = j | |e|) \) to be uniform 
(i.e. equal to \( \frac{1}{|{\bf e}|} \)), so the likelihood 
only depends upon the conditional word translation parameters \( P(f | e) \).
</p>

<p>The iterative EM update for this model is straightforward. For every 
pair of an English word type
\( e \) and a French word type \( f \), you count up the expected 
(fractional) number of times tokens \(f\) are aligned to tokens of
 \(e\) and normalize over values of \(e\). That will give you a new
estimate of the translation probabilities \(P (f |e)\), which leads 
to new alignment posteriors, and so on. We recommend developing on a small 
data set (1000 sentenes) and only 
a few iterations of EM.  When you are finished, you should see some 
improvements in your alignments.</p>

<p>Developing a Model 1 aligner should be enough to beat our baseline system
and earn seven points. But alignment isn't a solved problem, and the goal of
this assignment isn't for you to just implement a well-known algorithm (in
fact, you are not required to implement Model 1 at all, as long as you can 
beat it). To get full credit you'll need to experiment.
Here are some ideas:</p>

<ul class="real">
  <li>Implement an HMM aligner
    <a href="http://aclweb.org/anthology-new/C/C96/C96-2141.pdf">(paper)</a>.
  </li>
  <li>Add a sparse prior to word alignment probabilities and learn the model using Bayesian inference
    <a href="http://aclweb.org/anthology/P/P11/P11-2032.pdf">(paper)</a>.
  </li>
  <li>Train a French-English model and an English-French model, then 
    combine their predictions in some way 
    <a href="http://aclweb.org/anthology-new/N/N06/N06-1014.pdf">(paper)</a>.
  </li>
  <li>Train a supervised discriminative feature-based aligner using the annotated development set.
    <a href="http://aclweb.org/anthology-new/P/P06/P06-1009.pdf">(paper)</a>.
  </li>
  <li>Train an unsupervised feature-based aligner using the annotated development set.
    <a href="http://aclweb.org/anthology-new/P/P11/P11-1042.pdf">(paper)</a>.
  </li>
  <li><a href="http://scholar.google.com/scholar?q=word+alignment">Seek out
    additional inspiration</a>.
  </li>
</ul>

<p>But the sky's the limit! You can try anything you want as long as you
follow the ground rules:

<a name="rules"></a>
<h2>Ground Rules</h2>

<ul class="real">
<li>
   You may work in independently or in groups of any size, under these 
   conditions: 
   <ol>
   <li>
   You must notify us by posting a public note to piazza.
   </li>
   <li>
   Everyone in the group will receive the same grade on the assignment. 
   </li>
   <li>
   You can add people or merge groups at any time before the assignment is
   due. HOWEVER, you cannot drop people from your group once you've added them.
   <b>Collaboration is fine with us</b>, but 
   adjudicating Rashomon-style stories about who did or did not
   contribute is not. 
   </li>
  </ol>
</li>
<li> You must turn in three things:
  <ol class="real">
  <li>
  An alignment of the entire dataset. You can upload new output as often
  as you like, up until the assignment deadline. The output will be evaluated 
  using a secret metric, but the <tt>grade</tt> program will give you a good
  idea of how well you're doing, and you can use the <tt>check</tt> program
  to see whether your output is formatted correctly. Whoever has
  the highest score at the deadline will receive the most bonus points.
  </li>
  <li>
  Your code. You may make it available publicly (by uploading to
  github and sending us the URL), or privately (via email, in a tarball
  including your code and git revision history). This is due at the
  deadline: when you upload your final answer, send us the code.
  You are free to extend the code we provide or roll your own in whatever
  langugage you like, but the code should be self-contained, 
  self-documenting, and easy to use. 
  </li>
  <li>
  A brief description of your algorithm, posted to piazza. This can
  be of any length, as long as it is clear what you did.
  You have an additional two days to do this.
  </li>
  </ol>
</li>
<li>
   You may only use data or code resources other than the ones we
   provide <b>with advance permission</b>. We'll probably ask you to make 
   your resources available to everyone. So if, say, you have a cool idea 
   for using the Berkeley parser, or a French-English dictionary, that's 
   great. But to make things fair everyone should have access to the same 
   set of resources, so we'll ask you to share the parses. This kind of 
   constrained data condition is common in real-world evaluations of AI 
   systems, to make evaluations fair. In keeping with this philosophy, 
   we're much more likely to approve your request if 
   you ask <b>early</b>. Do not ask the night before the assignment. 
   A few things are off-limits:
   Giza++, the Berkeley Aligner, or anything else that
   already does the alignment for you. You must write your
   own code for alignment. If you want to do system combination, join
   forces with your classmates.
</li>
</ul>
<p>If you have any questions or you're confused about anything, 
<a href="https://piazza.com/jhu/spring2012/en600468">just ask</a>.


<p><em>Credits: This assignment is adapted from one originally developed by 
<a href="http://homepages.inf.ed.ac.uk/pkoehn/">Philipp Koehn</a>, 
and later modified by <a href="http://www.denero.org/">John DeNero</a>.
</p>

<div class="footer">
  <p>Last updated on {{ site.time | date: "%B %d, %Y" }}.  Site created using 
  <a href="http://git-scm.com/">git</a>,
  <a href="http://github.com/mojombo/jekyll/tree/master">jekyll</a>,
  and <a href="http://www.gnu.org/software/emacs/">emacs</a>, and hosted on <a href="https://github.com/">github</a>.</p>
  <p><a rel="license" href="http://creativecommons.org/licenses/by/3.0/">
    <img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by/3.0/80x15.png" /></a><br />
      Except where noted, the lectures, assignments, and other material hosted on this page were created by
      <span xmlns:cc="http://creativecommons.org/ns#" property="cc:attributionName">Adam Lopez, Chris Callison-Burch, and Matt Post</span> and are licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/3.0/">Creative Commons Attribution 3.0 Unported License</a>.
  That means you're  ree to reuse the 
  <a href="http://github.com/mt-class/mt-class.github.com">source code</a>, though please acknowledge that you got it from us. Thanks!</p>
</div>


</body></html>
